{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "*Supporting textbook chapters for week 11: Chapters 10.3&4*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=\"32\">**Fill out the online evaluations!!!**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Previously, in PHY407...\n",
    "\n",
    "Q on the chat last week: \n",
    "> *is MonteCarlo used to find the normalization factor in QM?* \n",
    "\n",
    "See here for applications of MC techniques in QM:\n",
    "\n",
    "> https://en.wikipedia.org/wiki/Quantum_Monte_Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Last week:\n",
    "* How to draw random numbers: PRNGs\n",
    "    * how to \"fake\" random draws (linear congruential generator for illustration);\n",
    "    * how to test: statistical properties of distributions;\n",
    "* Python's (pseudo) random number generator is the Mersenne Twister\n",
    "* Transformation of distributions, e.g., for uniformly distributed distribution $p(x)=a\\exp(-ax)$ obtained from\n",
    "$$x = -\\frac{1}{a}\\ln(1-z).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "* Monte Carlo integration:\n",
    "    * when functions are pathological (fast variations),\n",
    "    * when integrating over a lot of dimensions,\n",
    "    * when integration domains are complicated.\n",
    "    \n",
    "* MC integration techniques:\n",
    "    * Hit-or-miss\n",
    "    * Mean-value\n",
    "    * **Importance sampling** (we will use it this week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Importance sampling**\n",
    "\n",
    "* Hit or Miss integration and mean value method have errors that vary as  $N^{-1/2}$\n",
    "* Importance sampling chooses weights that favour largest integration values:\n",
    "$$I = \\int_a^b f(x)\\text dx = \\left<\\frac{f(x)}{w(x)}\\right>_w \\int_a^b w(x)\\text dx,$$\n",
    "\n",
    "    $$\\left<\\frac{f(x)}{w(x)}\\right>_w = \\frac{\\int_a^b\\left[\\frac{f(x)}{w(x)}\\right] w(x) \\text dx}{\\int_a^b w(x)\\text dx} \\approx \\frac1N \\sum_{i=1}^N\\frac{f(x_i)}{w(x_i)},$$\n",
    "    with the $x_i$'s draw from non-uniform distribution, with probability\n",
    "    $$p(x) = \\frac{w(x)}{\\int_a^b w(x) \\text d x}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Week 10, topics:\n",
    "* Monte Carlo simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font size=\"32\">**Fill out the online evaluations!!!**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Monte Carlo simulations:**\n",
    "\n",
    "> Any simulation that uses random numbers to simulate random physical processes to estimate something about the outcome of that process.\n",
    "\n",
    "    Newman, p. 476.\n",
    "\n",
    "We focus on statistical mechanics here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Statistical mechanics: a review\n",
    "\n",
    "* For a system in equilibrium at temperature $T$ (canonical ensemble), the probability of finding the system in any particular microstate $i$ is given by the Boltzmann distribution,\n",
    "$$P(E_i) = \\frac{\\exp\\left[-E_i/(k_B T)\\right]}{Z}, \\quad Z = \\sum_{i=1}^{ALL}\\exp\\left[-E_i/(k_B T)\\right]$$\n",
    "where $E_i$ is the energy of microstate $i$, and $k_B$ is Boltzmann's constant.\n",
    "\n",
    "* System at temperature $T$ undergoes transitions between microstates with probability of being in a particular microstate $P(E_i)$ \n",
    "* To calculate a macroscopic property during a measurement (total energy, magnetization...) $\\Rightarrow$ average over the many microstates that the system visits during the measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* If we want to measure a quantity \"$X$\" over the macrostate:\n",
    "    $$\\left<X\\right> = \\sum_{i=1}^{ALL}X_i P(E_i)$$\n",
    "    where $X_i$ is the value of the quantity in the $i^\\text{th}$ microstate and $P$ is the probability of finding the system in that microstate. \n",
    "* Simple example: single mole of gas has $N_A \\approx 6\\times 10^{23}$ molecules.\n",
    "    Assume each molecule had only 2 possible quantum states (gross underestimation), then the total number of microstates of the mole of gas is $2^{N_A}$, which is huge.\n",
    "* If we want to get any  useful macroscopic information $\\left<X\\right>$ about the system, we need to be more clever about how we count than just brute-force counting everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Monte Carlo simulation in Stat. Mech.\n",
    "\n",
    "$$\\text{Recall}\\quad P(E_i) = \\frac{\\exp\\left[-E_i/(k_B T)\\right]}{Z}, \\quad Z = \\sum_{i=1}^{ALL}\\exp\\left[-E_i/(k_B T)\\right]$$\n",
    "\n",
    "## Setting the problem\n",
    "\n",
    "* Huge number of terms in sum $\\Rightarrow$ use Monte Carlo summation.\n",
    "* Two difficulties to overcome:\n",
    "    1. properly sampling which terms to sum over (*solution: importance sampling*),\n",
    "    2. estimating $Z$ (*solution: Markov Chain Monte Carlo*)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Difficulty #1: why do we have to choose which terms to sum over?**\n",
    "\n",
    "*(We will get to difficulty #2 later)*\n",
    "\n",
    "* Randomly sample the terms in the sum and only use those as an estimate. Replace\n",
    "    $$\\left<X\\right> = \\sum_{i=1}^{ALL}X_i P(E_i)$$\n",
    "    with a sum over $N$ randomly sampled microstates,\n",
    "    $$\\left<X\\right> = \\frac{\\sum_{i=1}^{N}X_i P(E_i)}{\\sum_{i=1}^{N}P(E_i)}.$$\n",
    "* The denominator is needed to ensure the total probability over the sampled states is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* It is only worth keeping the big terms in the sum if we want to compute this:\n",
    "    $$\\left<X\\right> = \\sum_{i=1}^{ALL}X_i P(E_i)$$\n",
    "* There are a lot of states with $P(E_i)$ really small, with $E_ i \\gg k_B T$, which is the case for most of the states:\n",
    "    $$P(E_i) = \\frac{\\exp\\left[-E_i/(k_B T)\\right]}{Z}$$\n",
    "* To get a good estimate for the sum, need to preferentially choose terms where the integrand is non-negligible, but assign them less weight individually to not bias the final estimate.\n",
    "* So we should use importance sampling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Importance sampling for Stat. Mech.\n",
    "\n",
    "* For a continuous integral,\n",
    "$$I = \\int_a^b f(x)\\text dx = \\left<\\frac{f(x)}{w(x)}\\right>_w \\int_a^b w(x)\\text dx \\approx \\frac1N \\sum_{i=1}^N\\frac{f(x_i)}{w(x_i)}\\int_a^b w(x)\\text dx.$$\n",
    "* For a dicrete sum (see p. 478),\n",
    "$$\\left<X\\right> = \\sum_{i=1}^{N}X_i P(E_i) \\approx \\frac1N \\sum_{k=1}^{N}\\frac{X_k P(E_k)}{w_k} \\sum_{i=1}^{ALL}w_i.$$\n",
    "* What to choose for weight $w$ to reduce the variance? $P(E_i)$ of course!\n",
    "$$\\left<X\\right> \\approx \\frac1N \\sum_{k=1}^{N}\\underbrace{\\frac{X_k P(E_k)}{P(E_k)}}_{= X_k} \\underbrace{\\sum_{i=1}^{ALL}P(E_i)}_{=1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the end,\n",
    "$$\\left<X\\right> \\approx \\frac1N \\sum_{k=1}^{N} X_k.$$\n",
    "* Looks simple and no different from mean-value MC,\n",
    "* but recall that the $X_k$'s are drawn from non-uniform distribution: we randomly choose terms in the sum based on their Boltzmann probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* One thing left to deal with: How do we pick states with probability $P(E_k)$? Recall:\n",
    "    $$P(E_i) = \\frac{\\exp\\left[-E_i/(k_B T)\\right]}{Z}, \\quad Z = \\sum_{i=1}^{ALL}\\exp\\left[-E_i/(k_B T)\\right]$$\n",
    "\n",
    "* To do it this way, we need $Z$, which is a sum over all states. But if we could do this, we wouldn't need Monte Carlo in the first place!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Markov chain method\n",
    "\n",
    "### Elevator Pitch\n",
    "\n",
    "Mish-mashing https://en.wikipedia.org/wiki/Markov_chain and https://en.wikipedia.org/wiki/Markov_property,\n",
    "\n",
    "> A Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. [...] (sometimes characterized as \"memorylessness\"). In simpler terms, it is a process for which predictions can be made regarding future outcomes based solely on its present state [...]. In other words, conditional on the present state of the system, its future and past states are independent.\n",
    "\n",
    "* Random walks (Brownian motion) are Markov chains.\n",
    "* Here: events are jumps in energy states, one after another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Solution: Use the Markov chain method.\n",
    "* Text goes into details on how to implement this method with a Metropolis algorithm.\n",
    "* Crucial key: Metropolis does not compute probability to be in one state, but probability to transition between two states ($Z$ cancels out in the process).\n",
    "* I will summarize it algorithmically first, then briefly outline why it works mathematically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "![No, not this one either... https://en.wikipedia.org/w/index.php?curid=8913129](Metropolisposter.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Algorithm\n",
    "\n",
    "1. Choose a random starting state $i$\n",
    "2. Calculate the energy of that state $E_i$\n",
    "3. Choose a transition to a new state $j$ uniformly at random from allowed set\n",
    "4. Calculate the energy of this new state, $E_j$\n",
    "5. Calculate the acceptance probability for this transition:\n",
    "    * $P_a = 1\\qquad\\qquad \\qquad \\quad \\text{if}\\ E_j \\leq E_i$ (always accept a lower energy state)\n",
    "    * $\\displaystyle P_a = \\exp\\left(-\\frac{E_j - E_i}{k_B T}\\right) \\quad \\text{if}\\ E_j > E_i$ (accept a higher energy state sometimes, more often for high $T$).\n",
    "6. Accept/reject the move according to the acceptance probability\n",
    "7. Measure the quantity $X$ you want in its current state (new or old $i$) & store it\n",
    "8. Repeat from step 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* How to implement the probability of the event in the previous slide?\n",
    "    * $P_a = 1\\qquad\\qquad \\qquad \\quad \\text{if}\\ E_j \\leq E_i$ (always accept a lower energy state)\n",
    "    * $\\displaystyle P_a = \\exp\\left(-\\frac{E_j - E_i}{k_B T}\\right) \\quad \\text{if}\\ E_j > E_i$ (sometimes accept a higher energy state, more often for hight $T$).\n",
    "\n",
    "* Draw a random number in $[0,1)$. The statement\n",
    "\n",
    "    `if random() < exp(-(Ej-Ei)/kT):`\n",
    "\n",
    "    will introduce what to do if the move is accepted (`elif` will introduce what to do if rejected).\n",
    "* E.g., at very high $T$, $\\exp \\approx 1$ and almost all moves are accepted.\n",
    "* E.g., at low $T$, say, $\\exp[-\\Delta E/(k_BT)] = 1\\%$, then `random()` has 1% chance of drawing a number that is $<1\\%$.\n",
    "* If $E_j \\leq E_i$, then $\\exp \\geq 1$ and `if` statement automatically accepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Why does it work?\n",
    "\n",
    "* Why do the probability transitions move-by-move (Metropolis algorithm) end up creating a system where each microstate has a probability $P(E_i)$, the Boltzmann distribution?\n",
    "* Let $\\tau_{ij}$ a transition probability from $\\mu$-state $i$ to $\\mu$-state $j$, such that\n",
    "    $$\\frac{\\tau_{ij}}{\\tau_{ji}} = \\frac{P(E_j)}{P(E_i)},$$\n",
    "    which the Metropolis algorithm satisfies (see p. 482). For example, a small ratio above means that \"*$j$ is much less probable than $i$*\" and equivalently, \"*probability of $j\\to i$ is much higher than $i\\to j$*\", in equal amounts.\n",
    "* \"In equal amounts\" is crucial: it means that if you start from any initial state, your system will progressively evolve towards one where all $\\mu$-states follow Boltzmann.\n",
    "* Does it always converge? Could it converge to another distribution? If you love linear algebra and eigenvectors, see proof in Appendix D of Newman (it is actually quite elegant)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Ising model\n",
    "\n",
    "### Elevator Pitch\n",
    "\n",
    "* Simple model of ferromagnetism, but demonstrates many of the physical characteristics of fancier models.\n",
    "* Assume an object is made up of a collection of dipoles (e.g., electron spins) and the net magnetization is the sum of the magnetization of all the spins.\n",
    "* Ising model: \n",
    "    * assume the spins can only point up or down.\n",
    "    * the spins interact and favor parallel alignment of pairs of spins\n",
    "    * the interactions are non-zero only between nearest neighbours (i.e., distance dependent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The no-external-field macroscopic energy $E$ and magnetization $M$ are given by \n",
    "    $$E = -J\\sum_{\\left<ij\\right>} s_i s_j\\quad\\text{and}\\quad M = \\sum_{i}s_i$$\n",
    "    where $s = +1$ if spin is up & $s = -1$ if spin is down.\n",
    "\n",
    "* Notice that the lowest energy occurs if the spins all line up.\n",
    "\n",
    "* Spins can randomly flip as the system visits a set of allowable states given its temperature.  At any particular moment the system may look like\n",
    "![](Ising2D.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example in 1D\n",
    "\n",
    "* Create array of dipoles, initial state: random spin at each location.\n",
    "* Calculate energy & magnetization of state\n",
    "* Implement Metropolis algorithm:\n",
    "    * create new state: flip 1 spin randomly \n",
    "    * calculate new total energy\n",
    "    * calculate acceptance probability\n",
    "    * decide whether to accept or reject new state\n",
    "    * store 'new' energy & magnetization\n",
    "    * repeat  \n",
    "\n",
    "* After this is a starter code for lab 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Oh, and by the way..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<font size=\"32\">**Fill out the online evaluations!!!**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%load ising_1D_start.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot energy, magnetization\n",
    "fg, ax = plt.subplots(2, 1, sharex=True)\n",
    "ax[0].plot(magnet)\n",
    "ax[0].set_ylabel('Magnetization')\n",
    "ax[0].grid()\n",
    "ax[1].plot(energy)\n",
    "ax[1].set_xlabel('Number of flipping attempts')\n",
    "ax[1].set_ylabel('Energy')\n",
    "ax[1].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Simulated annealing\n",
    "\n",
    "## Elevator Pitch\n",
    "\n",
    "* Using Monte Carlo simulations to find **global** minima/maxima.\n",
    "* In week 4 we talked about ways of finding local minima (e.g., golden ratio search).\n",
    "* How it works:  rewrite max/min problem as looking for a \"ground state energy\" of a system.\n",
    "    * Function $f$ that you want the max/min of: make this the energy function.\n",
    "    * how could you find ground state: reduce temperature until you reach the ground state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Issue: if you reduce temperature too quickly: might get caught in a local min instead of the global min.\n",
    "* Solution: reduce temperature slowly.\n",
    "    This way system has time to explore many microstates and find a good approximation to the global minimum.\n",
    "* Visual Analogy: particle in a bumpy potential.\n",
    "    Too low energy: get stuck in nearest local minimum.\n",
    "    Keep low energy but allow some random 'kicks' in energy: can kick out of local minimum and continue heading to global minimum (see [this figure](https://commons.wikimedia.org/wiki/File:Hill_Climbing_with_Simulated_Annealing.gif#/media/File:Hill_Climbing_with_Simulated_Annealing.gif)).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![By Kingpin13 - Own work, CC0, https://commons.wikimedia.org/w/index.php?curid=25010763](Hill_Climbing_with_Simulated_Annealing.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: travelling salesman\n",
    "\n",
    "* Famous NP-hard problem (https://en.wikipedia.org/wiki/NP-hardness): what is the shortest route to visit a given set of locations on a map?\n",
    "* Want global minimum of distance\n",
    "* Start with random route, swap 2 cities, use Metropolis algorithm to determine whether to keep the swap\n",
    "* \"energy\" in this case is the total distance of the route\n",
    "* You can explore this problem using code from the book (`salesman.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![Newman's fig. 10.6](fig10-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font size=\"32\">**Fill out the online evaluations!!!**</font>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
